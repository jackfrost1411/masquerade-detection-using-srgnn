{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "import pickle\n",
    "from itertools import zip_longest\n",
    "import operator\n",
    "import datetime\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from io import StringIO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose = \"train_only\" #\"train_only\", \"train_test\", \"test_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = 'A' # train\n",
    "user2 = 'B' # test\n",
    "user1_name = user1\n",
    "user2_name = user2\n",
    "user1 = pd.read_pickle(user1+'.gzip')\n",
    "user2 = pd.read_pickle(user2+'.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecount</th>\n",
       "      <th>SID</th>\n",
       "      <th>SCount</th>\n",
       "      <th>CID</th>\n",
       "      <th>time</th>\n",
       "      <th>CMD</th>\n",
       "      <th>whole_cmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23_17:07:00_saguaro2_pts-0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23 17:07:04</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23_17:07:00_saguaro2_pts-0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-23 17:07:13</td>\n",
       "      <td>top</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23_17:07:00_saguaro2_pts-0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-23 17:07:30</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23_17:07:00_saguaro2_pts-0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-02-23 17:07:38</td>\n",
       "      <td>mkdir</td>\n",
       "      <td>mkdir D3cavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23_17:07:00_saguaro2_pts-0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-02-23 17:07:39</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639670</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-13_18:35:56_agave2_pts-39</td>\n",
       "      <td>4829</td>\n",
       "      <td>187989</td>\n",
       "      <td>2022-01-17 18:47:24</td>\n",
       "      <td>ls</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639671</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-13_18:35:56_agave2_pts-39</td>\n",
       "      <td>4829</td>\n",
       "      <td>187990</td>\n",
       "      <td>2022-01-17 18:47:29</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639672</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-13_18:35:56_agave2_pts-39</td>\n",
       "      <td>4829</td>\n",
       "      <td>187991</td>\n",
       "      <td>2022-01-17 18:47:55</td>\n",
       "      <td>cd</td>\n",
       "      <td>cd ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639673</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-13_18:35:56_agave2_pts-39</td>\n",
       "      <td>4829</td>\n",
       "      <td>187992</td>\n",
       "      <td>2022-01-17 18:58:13</td>\n",
       "      <td>cd</td>\n",
       "      <td>cd freq0.010_freq0.299/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639674</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-13_18:35:56_agave2_pts-39</td>\n",
       "      <td>4829</td>\n",
       "      <td>187993</td>\n",
       "      <td>2022-01-17 18:58:13</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>634802 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ecount                                 SID  SCount     CID  \\\n",
       "0            1  2016-02-23_17:07:00_saguaro2_pts-0       1       1   \n",
       "1            1  2016-02-23_17:07:00_saguaro2_pts-0       1       2   \n",
       "2            1  2016-02-23_17:07:00_saguaro2_pts-0       1       3   \n",
       "3            1  2016-02-23_17:07:00_saguaro2_pts-0       1       4   \n",
       "4            1  2016-02-23_17:07:00_saguaro2_pts-0       1       5   \n",
       "...        ...                                 ...     ...     ...   \n",
       "639670       1   2022-01-13_18:35:56_agave2_pts-39    4829  187989   \n",
       "639671       1   2022-01-13_18:35:56_agave2_pts-39    4829  187990   \n",
       "639672       1   2022-01-13_18:35:56_agave2_pts-39    4829  187991   \n",
       "639673       1   2022-01-13_18:35:56_agave2_pts-39    4829  187992   \n",
       "639674       1   2022-01-13_18:35:56_agave2_pts-39    4829  187993   \n",
       "\n",
       "                      time    CMD                whole_cmd  \n",
       "0      2016-02-23 17:07:04     ll                       ll  \n",
       "1      2016-02-23 17:07:13    top                      top  \n",
       "2      2016-02-23 17:07:30     ll                       ll  \n",
       "3      2016-02-23 17:07:38  mkdir           mkdir D3cavity  \n",
       "4      2016-02-23 17:07:39     ll                       ll  \n",
       "...                    ...    ...                      ...  \n",
       "639670 2022-01-17 18:47:24     ls                       ls  \n",
       "639671 2022-01-17 18:47:29     ll                       ll  \n",
       "639672 2022-01-17 18:47:55     cd                    cd ..  \n",
       "639673 2022-01-17 18:58:13     cd  cd freq0.010_freq0.299/  \n",
       "639674 2022-01-17 18:58:13     ll                       ll  \n",
       "\n",
       "[634802 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the timestamp to UNIX time\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "def f(x):\n",
    "    date, tm = str(x).split(\" \")\n",
    "    year, month, date = date.split(\"-\")\n",
    "    hr, mn, sec = tm.split(\":\")\n",
    "    #regular python datetime\n",
    "    date_time = datetime.datetime(int(year), int(month), int(date), int(hr), int(mn), int(sec))\n",
    "    #Returning unix timestamp after conversion\n",
    "    return int(time.mktime(date_time.timetuple()))\n",
    "\n",
    "user1['time'] = user1['time'].apply(f)\n",
    "user2['time'] = user2['time'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking the date from SID column\n",
    "def f(x):\n",
    "    return x[:10]\n",
    "\n",
    "user1['SID'] = user1['SID'].apply(f)\n",
    "user2['SID'] = user2['SID'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go on with renumbering sessions from 1!\n",
      "If your SCount column starts from some number other than 1!\n"
     ]
    }
   ],
   "source": [
    "#Renumbering of the sessions\n",
    "if list(user1['SCount'])[-1] == list(set(list(user1['SCount'])))[-1]:\n",
    "    print(\"Go on with renumbering sessions from 1!\")\n",
    "    print(\"If your SCount column starts from some number other than 1!\")\n",
    "    \n",
    "user1['SCount'] = user1['SCount'] - (list(user1['SCount'])[0]-1)\n",
    "user2['SCount'] = user2['SCount'] - (list(user2['SCount'])[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecount</th>\n",
       "      <th>SID</th>\n",
       "      <th>SCount</th>\n",
       "      <th>CID</th>\n",
       "      <th>time</th>\n",
       "      <th>CMD</th>\n",
       "      <th>whole_cmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1519173190</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1519173329</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-20</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1519181212</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-20</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1519181220</td>\n",
       "      <td>mkdir</td>\n",
       "      <td>mkdir document</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1519181221</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198854</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>1018</td>\n",
       "      <td>196827</td>\n",
       "      <td>1589230086</td>\n",
       "      <td>cd</td>\n",
       "      <td>cd sigma0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198855</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>1018</td>\n",
       "      <td>196828</td>\n",
       "      <td>1589230087</td>\n",
       "      <td>ls</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198856</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>1018</td>\n",
       "      <td>196829</td>\n",
       "      <td>1589230094</td>\n",
       "      <td>cat</td>\n",
       "      <td>cat job1.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198857</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>1018</td>\n",
       "      <td>196830</td>\n",
       "      <td>1589230375</td>\n",
       "      <td>ll</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198858</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>1018</td>\n",
       "      <td>196831</td>\n",
       "      <td>1589230377</td>\n",
       "      <td>ls</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197842 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ecount         SID  SCount     CID        time    CMD       whole_cmd\n",
       "0            2  2018-02-20       1       1  1519173190     ll              ll\n",
       "2            1  2018-02-20       2       3  1519173329     ll              ll\n",
       "5            2  2018-02-20       3       5  1519181212     ll              ll\n",
       "6            1  2018-02-20       3       6  1519181220  mkdir  mkdir document\n",
       "7            1  2018-02-20       3       7  1519181221     ll              ll\n",
       "...        ...         ...     ...     ...         ...    ...             ...\n",
       "198854       1  2020-05-11    1018  196827  1589230086     cd   cd sigma0.010\n",
       "198855       1  2020-05-11    1018  196828  1589230087     ls              ls\n",
       "198856       1  2020-05-11    1018  196829  1589230094    cat    cat job1.sh \n",
       "198857       1  2020-05-11    1018  196830  1589230375     ll              ll\n",
       "198858       1  2020-05-11    1018  196831  1589230377     ls              ls\n",
       "\n",
       "[197842 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label encode the commands\n",
    "le = LabelEncoder()\n",
    "le.fit(user1['CMD'])\n",
    "user1['CMD'] = le.transform(user1['CMD'])\n",
    "le_length = user1['CMD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197842/197842 [01:37<00:00, 2019.95it/s]\n"
     ]
    }
   ],
   "source": [
    "user2_cmd = []\n",
    "for cmd in tqdm(list(user2['CMD'])):\n",
    "    try:\n",
    "        user2_cmd += [le.transform([cmd])[0]]\n",
    "    except:\n",
    "        user2_cmd += [le_length+1]\n",
    "user2['CMD'] = user2_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique commands lenth for user1: 1290, user2: 193\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique commands lenth for user1: %d, user2: %d\"%(user1['CMD'].nunique(), user2['CMD'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's merge the sessions\n",
    "user2['SCount'] = user2['SCount'] + list(user1['SCount'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's merge two dataframes\n",
    "merged_users = pd.concat([user1, user2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecount</th>\n",
       "      <th>SID</th>\n",
       "      <th>SCount</th>\n",
       "      <th>CID</th>\n",
       "      <th>time</th>\n",
       "      <th>CMD</th>\n",
       "      <th>whole_cmd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1456272424</td>\n",
       "      <td>796</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1456272433</td>\n",
       "      <td>1176</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1456272450</td>\n",
       "      <td>796</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1456272458</td>\n",
       "      <td>885</td>\n",
       "      <td>mkdir D3cavity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-02-23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1456272459</td>\n",
       "      <td>796</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198854</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>5847</td>\n",
       "      <td>196827</td>\n",
       "      <td>1589230086</td>\n",
       "      <td>540</td>\n",
       "      <td>cd sigma0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198855</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>5847</td>\n",
       "      <td>196828</td>\n",
       "      <td>1589230087</td>\n",
       "      <td>828</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198856</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>5847</td>\n",
       "      <td>196829</td>\n",
       "      <td>1589230094</td>\n",
       "      <td>528</td>\n",
       "      <td>cat job1.sh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198857</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>5847</td>\n",
       "      <td>196830</td>\n",
       "      <td>1589230375</td>\n",
       "      <td>796</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198858</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>5847</td>\n",
       "      <td>196831</td>\n",
       "      <td>1589230377</td>\n",
       "      <td>828</td>\n",
       "      <td>ls</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832644 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ecount         SID  SCount     CID        time   CMD       whole_cmd\n",
       "0            1  2016-02-23       1       1  1456272424   796              ll\n",
       "1            1  2016-02-23       1       2  1456272433  1176             top\n",
       "2            1  2016-02-23       1       3  1456272450   796              ll\n",
       "3            1  2016-02-23       1       4  1456272458   885  mkdir D3cavity\n",
       "4            1  2016-02-23       1       5  1456272459   796              ll\n",
       "...        ...         ...     ...     ...         ...   ...             ...\n",
       "198854       1  2020-05-11    5847  196827  1589230086   540   cd sigma0.010\n",
       "198855       1  2020-05-11    5847  196828  1589230087   828              ls\n",
       "198856       1  2020-05-11    5847  196829  1589230094   528    cat job1.sh \n",
       "198857       1  2020-05-11    5847  196830  1589230375   796              ll\n",
       "198858       1  2020-05-11    5847  196831  1589230377   828              ls\n",
       "\n",
       "[832644 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1291"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(merged_users['CMD'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5335"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(merged_users['SCount'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_users.to_csv('merged_users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_split = int(list(user1['SCount'])[-1])\n",
    "dataset='merged_users.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5335\n",
      "5335\n",
      "Number of sessions after filtering 1 length sessions: 4446\n",
      "Avg Length of sessions:  57.52069275753486\n",
      "Counter({2: 172, 3: 161, 6: 131, 5: 115, 7: 114, 4: 112, 8: 103, 10: 98, 15: 97, 11: 88, 9: 87, 12: 81, 14: 73, 13: 73, 17: 71, 19: 63, 20: 60, 16: 57, 18: 56, 23: 53, 21: 53, 27: 52, 28: 51, 22: 48, 26: 45, 30: 44, 29: 42, 25: 41, 24: 40, 32: 38, 34: 37, 36: 37, 33: 36, 35: 36, 40: 32, 44: 30, 45: 29, 47: 28, 38: 28, 43: 28, 57: 27, 42: 27, 31: 26, 50: 25, 56: 25, 49: 24, 46: 24, 62: 21, 53: 21, 65: 21, 41: 21, 37: 21, 76: 20, 51: 20, 77: 20, 54: 20, 73: 20, 48: 19, 39: 19, 55: 18, 64: 18, 52: 17, 140: 17, 130: 17, 66: 16, 59: 16, 78: 16, 81: 16, 70: 16, 74: 16, 79: 16, 67: 15, 60: 15, 71: 15, 83: 14, 68: 14, 75: 14, 108: 14, 84: 13, 110: 13, 102: 12, 63: 12, 128: 12, 124: 11, 93: 11, 80: 11, 69: 11, 72: 11, 120: 11, 111: 11, 61: 11, 119: 11, 89: 11, 122: 11, 95: 11, 101: 11, 105: 10, 82: 10, 125: 10, 99: 10, 103: 10, 96: 10, 116: 10, 86: 10, 148: 10, 90: 10, 104: 10, 145: 10, 118: 10, 91: 10, 92: 10, 85: 9, 88: 9, 154: 9, 98: 9, 165: 9, 143: 9, 117: 9, 94: 9, 109: 8, 137: 8, 173: 8, 58: 8, 186: 8, 144: 8, 192: 7, 187: 7, 175: 7, 87: 7, 115: 7, 113: 7, 112: 7, 159: 7, 157: 7, 134: 7, 146: 7, 182: 7, 172: 7, 246: 7, 160: 6, 151: 6, 106: 6, 114: 6, 209: 6, 129: 6, 107: 6, 252: 6, 240: 6, 162: 6, 139: 6, 206: 6, 158: 6, 153: 6, 141: 6, 190: 6, 135: 6, 127: 6, 168: 6, 133: 6, 225: 6, 156: 5, 138: 5, 155: 5, 150: 5, 169: 5, 161: 5, 211: 5, 183: 5, 176: 5, 291: 5, 132: 5, 222: 5, 191: 5, 298: 5, 149: 5, 131: 5, 164: 5, 121: 5, 100: 5, 180: 5, 213: 5, 258: 5, 197: 5, 171: 5, 184: 4, 126: 4, 147: 4, 218: 4, 163: 4, 179: 4, 205: 4, 195: 4, 207: 4, 286: 4, 170: 4, 185: 4, 178: 4, 189: 4, 255: 4, 214: 4, 229: 4, 123: 4, 296: 4, 202: 4, 256: 4, 283: 4, 269: 4, 245: 3, 201: 3, 244: 3, 166: 3, 241: 3, 208: 3, 250: 3, 97: 3, 260: 3, 221: 3, 136: 3, 265: 3, 275: 3, 212: 3, 274: 3, 232: 3, 248: 3, 215: 3, 230: 3, 272: 3, 282: 3, 203: 3, 142: 3, 216: 3, 284: 3, 273: 3, 247: 3, 200: 3, 196: 3, 276: 2, 152: 2, 228: 2, 259: 2, 198: 2, 254: 2, 167: 2, 262: 2, 223: 2, 217: 2, 277: 2, 239: 2, 236: 2, 238: 2, 268: 2, 243: 2, 264: 2, 210: 2, 261: 2, 294: 2, 281: 2, 181: 2, 278: 2, 194: 2, 270: 2, 231: 2, 235: 2, 289: 2, 251: 2, 233: 2, 279: 2, 242: 2, 193: 2, 266: 1, 174: 1, 237: 1, 177: 1, 290: 1, 219: 1, 257: 1, 204: 1, 188: 1, 297: 1, 220: 1, 293: 1, 226: 1, 234: 1, 224: 1, 249: 1, 253: 1, 280: 1, 267: 1, 299: 1, 295: 1})\n",
      "\n",
      "Length of sess_commands before filtering less than 5 command counts: 4446\n",
      "\n",
      "1Length of training sessions sorted: 3597\n",
      "1Length of testing sessions sorted: 849\n",
      "Length of sess_commands after filtering less than 5 command counts: 3019\n",
      "\n",
      "2Length of training sessions sorted: 2170\n",
      "2Length of testing sessions sorted: 849\n",
      "Splitting sessions: 4829\n",
      "849\n",
      "\n",
      "Length of training sessions sorted: 2170\n",
      "Length of testing sessions sorted: 849\n",
      "\n",
      "First three training sessions: [('1', 1456210800.0), ('3', 1475046000.0), ('6', 1475046000.0)]\n",
      "First three test sessions: [('4833', 1519196400.0), ('4835', 1519196400.0), ('4836', 1519196400.0)]\n",
      "-- Splitting done: train set and test set @ 2022-04-04 13:43:09.796838s\n",
      "\n",
      "Number of unique commands (after all the filtering): 426\n",
      "\n",
      "Length of training sessions: 2170\n",
      "Length of testing sessions: 501\n",
      "15.163435430857906\n",
      "\n",
      "Length of new training sequences derived from all the sessions: 20993\n",
      "Length of new testing sequences derived from all the sessions: 5399\n",
      "Average length of sequence in the dataset training and testing combined:  10.880943466866341\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "reader = StringIO()\n",
    "merged_users.to_csv(reader)\n",
    "reader.seek(0)\n",
    "\n",
    "# reader = csv.DictReader(f, delimiter=',')\n",
    "sess_commands = {}\n",
    "sess_date = {}\n",
    "ctr = 0\n",
    "curid = -1\n",
    "curdate = None\n",
    "columns = {'':0, 'ecount':1, 'SID':2, 'SCount':3, 'CID':4, 'time':5, 'CMD':6, 'whole_cmd':7}\n",
    "for data in list(csv.reader(reader))[1:]:\n",
    "    sessid = data[columns['SCount']] #Session number\n",
    "    if curdate and not curid == sessid:\n",
    "\n",
    "        date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
    "        sess_date[curid] = date\n",
    "    curid = sessid #Current session id \n",
    "\n",
    "    command = data[columns['CMD']], int(data[columns['time']]) #The command id and timeframe of that command\n",
    "    curdate = data[columns['SID']] #Date of the session\n",
    "\n",
    "    if sessid in sess_commands:\n",
    "        sess_commands[sessid] += [command]\n",
    "    else:\n",
    "        sess_commands[sessid] = [command]\n",
    "    ctr += 1\n",
    "\n",
    "date = time.mktime(time.strptime(curdate, '%Y-%m-%d'))\n",
    "sess_date[curid] = date\n",
    "\n",
    "for i in list(sess_commands):\n",
    "    sorted_clicks = sorted(sess_commands[i], key=operator.itemgetter(1)) #Sorting the commands based on timeframe\n",
    "    sess_commands[i] = [c[0] for c in sorted_clicks]\n",
    "\n",
    "print(len(list(sess_commands)))\n",
    "\n",
    "\n",
    "def lensOfSessions():\n",
    "    return [len(sess_commands[s]) for s in list(sess_commands)]\n",
    "\n",
    "print(len(sess_commands))\n",
    "# Removing the same commands in sequence of 2 length\n",
    "for s in list(sess_commands):\n",
    "    sess_commands[s] = [i for i, j in zip_longest(sess_commands[s], sess_commands[s][1:]) if i != j]\n",
    "\n",
    "# Filter out length 1 sessions\n",
    "for s in list(sess_commands):\n",
    "    if len(sess_commands[s]) == 1 or len(sess_commands[s])>=300:\n",
    "        del sess_commands[s]\n",
    "        del sess_date[s]\n",
    "\n",
    "print(\"Number of sessions after filtering 1 length sessions:\", len(sess_commands))\n",
    "\n",
    "print(\"Avg Length of sessions: \", np.mean(lensOfSessions()))\n",
    "print(Counter(lensOfSessions()))\n",
    "\n",
    "# Count number of times each command appears\n",
    "commandid_counts = {}\n",
    "for s in sess_commands:\n",
    "    if int(s) <= session_split:\n",
    "        seq = sess_commands[s]\n",
    "        for commandid in seq:\n",
    "            if commandid in commandid_counts:\n",
    "                commandid_counts[commandid] += 1\n",
    "            else:\n",
    "                commandid_counts[commandid] = 1\n",
    "\n",
    "sorted_counts = sorted(commandid_counts.items(), key=operator.itemgetter(1))\n",
    "# print(sorted_counts)\n",
    "# Filtering commands appearing less than 5 times\n",
    "# Try this when you only consider the first word in one command\n",
    "length = len(sess_commands)\n",
    "print(\"\\nLength of sess_commands before filtering less than 5 command counts:\",len(sess_commands))\n",
    "dates = list(sess_date.items())\n",
    "tra_sess = filter(lambda x: int(x[0]) <= int(session_split), dates)\n",
    "tes_sess = filter(lambda x: int(x[0]) > int(session_split), dates)\n",
    "tra_sess = sorted(tra_sess, key=operator.itemgetter(1))\n",
    "tes_sess = sorted(tes_sess, key=operator.itemgetter(1))\n",
    "print(\"\\n1Length of training sessions sorted:\", len(tra_sess))\n",
    "print(\"1Length of testing sessions sorted:\", len(tes_sess))\n",
    "for s in list(sess_commands):\n",
    "    if int(s)<=session_split:\n",
    "        curseq = sess_commands[s]\n",
    "        filseq = list(filter(lambda i: commandid_counts[i] <= 5000 and commandid_counts[i] >= 2, curseq))\n",
    "        if len(filseq) < 2 and int(s)<=session_split:\n",
    "    #         print(curseq, filseq)\n",
    "            del sess_commands[s]\n",
    "            del sess_date[s]\n",
    "        else:\n",
    "            sess_commands[s] = filseq\n",
    "print(\"Length of sess_commands after filtering less than 5 command counts:\",len(sess_commands))\n",
    "dates = list(sess_date.items())\n",
    "tra_sess = filter(lambda x: int(x[0]) <= int(session_split), dates)\n",
    "tes_sess = filter(lambda x: int(x[0]) > int(session_split), dates)\n",
    "tra_sess = sorted(tra_sess, key=operator.itemgetter(1))\n",
    "tes_sess = sorted(tes_sess, key=operator.itemgetter(1))\n",
    "print(\"\\n2Length of training sessions sorted:\", len(tra_sess))\n",
    "print(\"2Length of testing sessions sorted:\", len(tes_sess))\n",
    "\n",
    "# Split out test set based on dates\n",
    "dates = list(sess_date.items())\n",
    "\n",
    "print('Splitting sessions:', session_split)\n",
    "tra_sess = filter(lambda x: int(x[0]) <= int(session_split), dates)\n",
    "tes_sess = filter(lambda x: int(x[0]) > int(session_split), dates)\n",
    "\n",
    "# Sort sessions by date\n",
    "tra_sess = sorted(tra_sess, key=operator.itemgetter(1))\n",
    "tes_sess = sorted(tes_sess, key=operator.itemgetter(1))\n",
    "\n",
    "print(len(tes_sess))\n",
    "\n",
    "print(\"\\nLength of training sessions sorted:\", len(tra_sess))\n",
    "print(\"Length of testing sessions sorted:\", len(tes_sess))\n",
    "print(\"\\nFirst three training sessions:\", tra_sess[:3])\n",
    "print(\"First three test sessions:\", tes_sess[:3])\n",
    "\n",
    "print(\"-- Splitting done: train set and test set @ %ss\" % datetime.datetime.now())\n",
    "\n",
    "command_dict = {}\n",
    "command_ctr = 1\n",
    "# Convert training sessions to sequences and renumber commands to start from 1\n",
    "def obtian_tra():\n",
    "    train_ids = []\n",
    "    train_seqs = []\n",
    "    train_dates = []\n",
    "    global command_ctr\n",
    "    for s, date in tra_sess:\n",
    "        seq = sess_commands[s] #The sequence of commands in this session\n",
    "        outseq = []\n",
    "        for i in seq:\n",
    "            if i in command_dict:\n",
    "                outseq += [command_dict[i]]\n",
    "            else:\n",
    "                outseq += [command_ctr]\n",
    "                command_dict[i] = command_ctr\n",
    "                command_ctr += 1\n",
    "        if len(outseq) < 2:  # Doesn't occur\n",
    "            continue\n",
    "        train_ids += [s]\n",
    "        train_dates += [date]\n",
    "        train_seqs += [outseq]\n",
    "    print(\"\\nNumber of unique commands (after all the filtering):\", command_ctr)     # 43098, 37484\n",
    "    return train_ids, train_dates, train_seqs\n",
    "\n",
    "# Convert test sessions to sequences, ignoring commands that do not appear in training set\n",
    "def obtian_tes():\n",
    "    test_ids = []\n",
    "    test_seqs = []\n",
    "    test_dates = []\n",
    "    for s, date in tes_sess:\n",
    "        seq = sess_commands[s]\n",
    "        outseq = []\n",
    "        for i in seq:\n",
    "            if i in command_dict:\n",
    "                outseq += [command_dict[i]]\n",
    "        if len(outseq) < 2:\n",
    "            continue\n",
    "        test_ids += [s]\n",
    "        test_dates += [date]\n",
    "        test_seqs += [outseq]\n",
    "    return test_ids, test_dates, test_seqs\n",
    "\n",
    "tra_ids, tra_dates, tra_seqs = obtian_tra() #Train session id/numbers, Train session dates, Train session sequence\n",
    "tes_ids, tes_dates, tes_seqs = obtian_tes() #Test session id/numbers, Test session dates, Test session sequence\n",
    "\n",
    "def process_seqs(iseqs, idates):\n",
    "    out_seqs = []\n",
    "    out_dates = []\n",
    "    labs = []\n",
    "    ids = []\n",
    "    for id, seq, date in zip(range(len(iseqs)), iseqs, idates):\n",
    "        for i in range(1, len(seq)):\n",
    "            tar = seq[-i]\n",
    "            labs += [tar]\n",
    "            out_seqs += [seq[:-i]]\n",
    "            out_dates += [date]\n",
    "            ids += [id]\n",
    "    return out_seqs, out_dates, labs, ids\n",
    "\n",
    "print(\"\\nLength of training sessions:\", len(tra_seqs))\n",
    "print(\"Length of testing sessions:\", len(tes_seqs))\n",
    "tr_seqs, tr_dates, tr_labs, tr_ids = process_seqs(tra_seqs, tra_dates)\n",
    "te_seqs, te_dates, te_labs, te_ids = process_seqs(tes_seqs, tes_dates)\n",
    "\n",
    "print(np.mean(np.array([len(i) for i in tr_seqs])))\n",
    "# print(Counter([len(i) for i in tr_seqs]))\n",
    "\n",
    "# tot_seqs = tr_seqs + te_seqs\n",
    "# tot_labs = tr_labs + te_labs\n",
    "# tot_seqs = np.asarray(tot_seqs, dtype=object)\n",
    "# tot_labs = np.asarray(tot_labs, dtype=object)\n",
    "# if True:\n",
    "#     shuffled_arg = np.arange(len(tot_seqs))\n",
    "#     np.random.shuffle(shuffled_arg)\n",
    "#     tot_seqs = tot_seqs[shuffled_arg]\n",
    "#     tot_labs = tot_labs[shuffled_arg]\n",
    "\n",
    "# split = int(len(tot_labs)*0.9)\n",
    "\n",
    "tra = (tr_seqs, tr_labs)\n",
    "tes = (te_seqs, te_labs)\n",
    "\n",
    "print(\"\\nLength of new training sequences derived from all the sessions:\", len(tra[0]))\n",
    "print(\"Length of new testing sequences derived from all the sessions:\", len(tes[0]))\n",
    "# print(tr_seqs[:3], tr_dates[:3], tr_labs[:3])\n",
    "# print(te_seqs[:3], te_dates[:3], te_labs[:3])\n",
    "all = 0\n",
    "\n",
    "for seq in tra_seqs:\n",
    "    all += len(seq)\n",
    "for seq in tes_seqs:\n",
    "    all += len(seq)\n",
    "print('Average length of sequence in the dataset training and testing combined: ', all/(len(tra_seqs) + len(tes_seqs) * 1.0))\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_ctr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../pytorch_code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/sse/.local/opt/conda/envs/shellprint/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import pickle\n",
    "import time\n",
    "from utils import build_graph, Data, split_validation\n",
    "from model import *\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "from torch import nn\n",
    "from torch.nn import Module, Parameter\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = [0,0,0]\n",
    "best_epoch = [0,0,0]\n",
    "bad_counter = 0\n",
    "\n",
    "def train(epoch, model, train_data):\n",
    "    #print('start training: ', datetime.datetime.now())\n",
    "    model.train()\n",
    "    total_loss = [0.0]\n",
    "    slices = train_data.generate_batch(model.batch_size)\n",
    "    pbar = tqdm(zip(slices, np.arange(len(slices))))\n",
    "    train_hit, train_mrr, train_acc = [], [], []\n",
    "    for i, j in pbar:\n",
    "        model.optimizer.zero_grad()\n",
    "        targets, scores = forward(model, i, train_data)\n",
    "#         print(targets.shape, scores.shape)\n",
    "        \n",
    "        train_sub_scores = scores.topk(5)[1]\n",
    "        train_sub_scores = trans_to_cpu(train_sub_scores).detach().numpy()\n",
    "#         print(np.array(train_sub_scores).shape)\n",
    "        \n",
    "        for score, target, mask in zip(train_sub_scores, targets, train_data.mask):\n",
    "            train_hit.append(np.isin(target - 1, score))\n",
    "            if len(np.where(score == target - 1)[0]) == 0:\n",
    "                train_mrr.append(0)\n",
    "            else:\n",
    "                train_mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "#                 print(score, target)\n",
    "#                 print((np.where(score == target - 1)[0][0] + 1))\n",
    "            \n",
    "            if score[0]==target-1: train_acc += [1]\n",
    "            else: train_acc+=[0]\n",
    "        \n",
    "        targets = trans_to_cuda(torch.Tensor(targets).long())\n",
    "        loss = model.loss_function(scores, targets - 1)\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "        total_loss += [loss.item()]\n",
    "        #f j % int(len(slices) / 5 + 1) == 0:\n",
    "        pbar.set_description('Epoch %d:[%d/%d] Train Loss:%.3f Train Accuracy:%.3f Train Precision@5:%.3f Train MRR@5:%.3f' % (epoch, j, len(slices), np.mean(total_loss), np.mean(train_acc), np.mean(train_hit), np.mean(train_mrr)))\n",
    "#     model.scheduler.step()\n",
    "#         print(np.array(train_hit).shape)\n",
    "    \n",
    "    train_hit = np.mean(train_hit) * 100\n",
    "    train_mrr = np.mean(train_mrr) * 100\n",
    "    train_acc = np.mean(train_acc) * 100\n",
    "    train_loss = np.mean(total_loss)\n",
    "    \n",
    "    return train_hit, train_mrr, train_acc, train_loss\n",
    "\n",
    "def test(model, test_data):\n",
    "    \n",
    "    total_loss = [0.0]\n",
    "    slices = test_data.generate_batch2(model.batch_size, 400)\n",
    "    print(np.array(slices).shape)\n",
    "    pbar = tqdm(zip(slices, np.arange(len(slices))))\n",
    "    results = []\n",
    "    \n",
    "    for i, j in pbar:\n",
    "        hit, mrr, acc = [], [], []\n",
    "        targets, scores = forward(model, i, test_data)\n",
    "#         print(np.array(targets).shape, np.array(scores).shape)\n",
    "        sub_scores = scores.topk(5)[1]\n",
    "        sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
    "#         print(np.array(sub_scores).shape)\n",
    "        for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
    "            hit.append(np.isin(target - 1, score))\n",
    "            if len(np.where(score == target - 1)[0]) == 0:\n",
    "                mrr.append(0)\n",
    "            else:\n",
    "                mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
    "#                 print((np.where(score == target - 1)[0][0] + 1))\n",
    "\n",
    "            if score[0]==target-1: acc += [1]\n",
    "            else: acc+=[0]\n",
    "        \n",
    "        targets = trans_to_cuda(torch.Tensor(targets).long())\n",
    "        loss = model.loss_function(scores, targets - 1)\n",
    "        total_loss += [loss.item()]\n",
    "        \n",
    "        results.append([loss.item(), np.mean(acc), np.mean(hit), np.mean(mrr)])\n",
    "        \n",
    "        pbar.set_description('[%d/%d] Test Loss:%.3f Test Accuracy:%.3f Test Precision@5:%.3f Test MRR@5:%.3f' % (j, len(slices), np.mean(total_loss), np.mean(acc), np.mean(hit), np.mean(mrr)))\n",
    "#         print(np.array(hit).shape)\n",
    "    res = pd.DataFrame(results, columns=['test_loss', 'test_acc', 'test_hit', 'test_mrr'])\n",
    "    res.to_csv(\"Test.csv\")\n",
    "    hit = np.mean(hit) * 100\n",
    "    mrr = np.mean(mrr) * 100\n",
    "    acc = np.mean(acc) * 100\n",
    "    loss = np.mean(total_loss)\n",
    "    \n",
    "    return hit, mrr, acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "purpose = 'test_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17402it [00:00, 125114.68it/s]\n",
      "100%|██████████| 17402/17402 [00:00<00:00, 195586.80it/s]\n",
      "3961it [00:00, 875738.66it/s]\n",
      "100%|██████████| 3961/3961 [00:00<00:00, 496492.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = Data(tra, shuffle=True)\n",
    "test_data = Data(tes, shuffle=True)\n",
    "\n",
    "class opt:\n",
    "        def __init__(self):\n",
    "            self.batchSize=200\n",
    "            self.dataset='sample'\n",
    "            self.epoch=100\n",
    "            self.hiddenSize=100\n",
    "            self.l2=1e-05\n",
    "            self.lr=0.001\n",
    "            self.lr_dc=0.1\n",
    "            self.lr_dc_step=3\n",
    "            self.n_node=232\n",
    "            self.nonhybrid=False\n",
    "            self.patience=10\n",
    "            self.step=1\n",
    "            self.valid_portion=0.1\n",
    "            self.validation=False\n",
    "opt=opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[399/400] Test Loss:2.503 Test Accuracy:0.465 Test Precision@5:0.775 Test MRR@5:0.583: : 400it [00:37, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:2.5031 Test Accuracy:46.5000 Test Precision@5:77.5000 Test MRR@5:58.2833\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if purpose=='train_only':\n",
    "    \n",
    "    model = SessionGraph(opt, command_ctr)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    for epoch in range(opt.epoch):\n",
    "\n",
    "        train_hit, train_mrr, train_acc, train_loss = train(epoch, model, train_data)\n",
    "        print(\"Train Loss:%.4f Train Accuracy:%.4f Train Precision@5:%.4f Train MRR@5:%.4f\\n\"% (train_loss, train_acc, train_hit, train_mrr))\n",
    "        flag = 0\n",
    "        if train_hit >= best_result[0]:\n",
    "            best_result[0] = train_hit\n",
    "            best_epoch[0] = epoch\n",
    "            flag = 1\n",
    "        if train_mrr >= best_result[1]:\n",
    "            best_result[1] = train_mrr\n",
    "            best_epoch[1] = epoch\n",
    "            flag = 1\n",
    "        if train_acc >= best_result[2]:\n",
    "            best_result[2] = train_acc\n",
    "            best_epoch[2] = epoch\n",
    "            flag = 1\n",
    "\n",
    "    print('Best Result:')\n",
    "    print('\\tRecall@20:\\t%.4f\\tMRR@5:\\t%.4f\\tEpoch:\\t%d,\\t%d'% (best_result[0], best_result[1], best_epoch[0], best_epoch[1]))\n",
    "\n",
    "    model_name = user1_name+'_model.pth'\n",
    "    print('Saving final model states to {}...'.format('model/'+model_name))\n",
    "    torch.save(model.state_dict(), '../model/'+model_name)\n",
    "\n",
    "elif purpose=='train_test':\n",
    "    results = []\n",
    "    model = SessionGraph(opt, command_ctr)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    for epoch in range(opt.epoch):\n",
    "\n",
    "        train_hit, train_mrr, train_acc, train_loss = train(epoch, model, train_data)\n",
    "        print(\"Train Loss:%.4f Train Accuracy:%.4f Train Precision@5:%.4f Train MRR@5:%.4f\\n\"% (train_loss, train_acc, train_hit, train_mrr))\n",
    "        model.eval()\n",
    "        test_hit, test_mrr, test_acc, test_loss = test(model, test_data)\n",
    "        print(\"Test Loss:%.4f Test Accuracy:%.4f Test Precision@5:%.4f Test MRR@5:%.4f\\n\"% (test_loss, test_acc, test_hit, test_mrr))\n",
    "        results.append([train_loss, train_acc, train_hit, train_mrr, test_loss, test_acc, test_hit, test_mrr])\n",
    "        flag = 0\n",
    "        if train_hit >= best_result[0]:\n",
    "            best_result[0] = train_hit\n",
    "            best_epoch[0] = epoch\n",
    "            flag = 1\n",
    "        if train_mrr >= best_result[1]:\n",
    "            best_result[1] = train_mrr\n",
    "            best_epoch[1] = epoch\n",
    "            flag = 1\n",
    "        if train_acc >= best_result[2]:\n",
    "            best_result[2] = train_acc\n",
    "            best_epoch[2] = epoch\n",
    "            flag = 1\n",
    "\n",
    "    res = pd.DataFrame(results, columns=['train_loss', 'train_acc', 'train_hit', 'train_mrr', 'test_loss', 'test_acc', 'test_hit', 'test_mrr'])\n",
    "    \n",
    "    print('Best Result:')\n",
    "    print('\\tRecall@20:\\t%.4f\\tMRR@5:\\t%.4f\\tEpoch:\\t%d,\\t%d'% (best_result[0], best_result[1], best_epoch[0], best_epoch[1]))\n",
    "\n",
    "    model_name = user1_name+'_model.pth'\n",
    "    print('Saving final model states to {}...'.format('model/'+model_name))\n",
    "    torch.save(model.state_dict(), '../model/'+model_name)\n",
    "    res.to_csv('../model/'+user1_name+'_'+user2_name+'_model.csv')\n",
    "    \n",
    "elif purpose=='test_only':\n",
    "    test_model = SessionGraph(opt, command_ctr)\n",
    "    test_model = test_model.cuda()\n",
    "    \n",
    "    test_model_name = user1_name+'_model.pth'\n",
    "    test_model.load_state_dict(torch.load('../model/'+test_model_name))\n",
    "    test_model.eval()\n",
    "\n",
    "    test_hit, test_mrr, test_acc, test_loss = test(test_model, test_data)\n",
    "\n",
    "    print(\"Test Loss:%.4f Test Accuracy:%.4f Test Precision@5:%.4f Test MRR@5:%.4f\\n\"% (test_loss, test_acc, test_hit, test_mrr))\n",
    "#     except:\n",
    "#         print(\"Can't find the model!\")\n",
    "\n",
    "else:\n",
    "    print(\"Choose the right option.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 9, 34]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "a = [1,2,3,4,5,6,7,8,9,10,11,34]\n",
    "random.choices(a, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3, 4]), array([5, 6, 7, 8, 9])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.split(np.arange(10), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "filename = '../model/'+user1_name+'_'+user2_name+'_model.csv'\n",
    "\n",
    "history = pd.read_csv(filename, sep=',')\n",
    "'train_loss', 'train_acc', 'train_hit', 'train_mrr', 'test_loss', 'test_acc', 'test_hit', 'test_mrr'\n",
    "train_acc = history['train_acc']\n",
    "train_hit = history['train_hit']\n",
    "train_loss = history['train_loss']\n",
    "train_mrr = history['train_mrr']\n",
    "\n",
    "test_acc = history['test_acc']\n",
    "test_hit = history['test_hit']\n",
    "test_loss = history['test_loss']\n",
    "test_mrr = history['test_mrr']\n",
    "\n",
    "epochs = range(opt.epoch)\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(epochs, train_acc, 'b', label='Train Accuracy')\n",
    "plt.plot(epochs, test_acc, 'r', label='Test Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(epochs, train_hit, 'b', label='Train Precision@5')\n",
    "plt.plot(epochs, test_hit, 'r', label='Test Precision@5')\n",
    "plt.title('Precision@5')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(epochs, train_mrr, 'b', label='Train MRR@5')\n",
    "plt.plot(epochs, test_mrr, 'r', label='Test MRR@5')\n",
    "plt.title('MRR@5')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(epochs, train_loss, 'b', label='Train Loss')\n",
    "plt.plot(epochs, test_loss, 'r', label='Test Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "\n",
    "plt.savefig(filename[:-10]+'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
